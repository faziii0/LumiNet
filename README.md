# LumiNet

A Multi-Modal Feature Fusion Network for 3D Object Detection

---

# ğŸš€ Code Availability
> Code will be available soon.

<!-- 
![Fusion-new drawio](https://github.com/faziii0/LumiNet/assets/111413133/bfea5354-d194-4cfd-8ef4-138d72fb807f)
-->

---

# ğŸ–¥ï¸ Environment Setup

- Linux (tested on Ubuntu 22.04)
- Python 3.8
- PyTorch 1.10 + CUDA 11.3

---

# âš™ï¸ Installation

To deploy this project, run:


git clone https://github.com/faziii0/LumiNet
cd LumiNet




conda create -n liard python=3.8
conda activate liard

conda install pytorch=1.10.0 torchvision=0.11.0 torchaudio=0.10.0 cudatoolkit=11.3 -c pytorch -c conda-forge
conda install -c conda-forge cudatoolkit-dev

pip install -r requirements.txt
sh build_and_install.sh


## Depth Images
We use [MiDaS](https://github.com/isl-org/MiDaS) pretrained model to covert image_2 into depth images or download it from here Google. You can clone their repo and run this command
bash
python run.py --model_type dpt_beit_large_512 --input_path image_2 --output_path depth

---

# ğŸ“š Dataset Preparation

Please download the official [KITTI 3D object detection](https://www.cvlibs.net/datasets/kitti/eval_object.php?obj_benchmark=3d) dataset and  train mask from [Epnet++](https://github.com/happinesslz/EPNetV2)


LiARD
â”œâ”€â”€ data
â”‚   â”œâ”€â”€ KITTI
â”‚   â”‚   â”œâ”€â”€ ImageSets
â”‚   â”‚   â”œâ”€â”€ object
â”‚   â”‚   â”‚   â”œâ”€â”€ training
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ calib
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ velodyne
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ label_2
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ image_2
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ depth
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ train_mask
â”‚   â”‚   â”‚   â”œâ”€â”€ testing
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ calib
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ velodyne
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ image_2
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ depth
â”œâ”€â”€ lib
â”œâ”€â”€ pointdep_lirad
â”œâ”€â”€ tools



## Trained Model Evaluation





| Objects | Easy|Moderate     | Hard                   | 
| :-------- | :------- | :----------- | :----------|
| Car | 91.67% | 83.32% | 78.29%
| Pedestrian | 00.0% | 00.0% | 0.00%
| Cyclist | 00.0% | 00.0% | 00.0%

3D Predicted labels are avialable from the above Google


## Acknowledgements

 Thanks to all the contributors and authors of the project [PointRCNN](https://github.com/sshaoshuai/PointRCNN), [EPNet++](https://github.com/happinesslz/EPNetV2), [EPNet](https://github.com/happinesslz/EPNet),[MiDaS](https://github.com/isl-org/MiDaS)

## Citation
